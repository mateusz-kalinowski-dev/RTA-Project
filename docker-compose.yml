
name: rta-project
services:
  # Kafka and Zookeeper setup with Redpanda Console
  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:latest-ubi8
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    depends_on:
      - zookeeper
    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: on-failure
    networks:
      - rta-network

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:latest-ubi8
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    restart: on-failure
    networks:
      - rta-network
  
  redpanda-console:
    image: docker.redpanda.com/redpandadata/console:latest
    container_name: redpanda-console
    ports:
      - "8080:8080"
    environment:
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - kafka
    restart: on-failure
    networks:
      - rta-network

  # Databases
  mongodb:
    container_name: mongodb
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    restart: on-failure
    networks:
      - rta-network

  postgres:
    image: postgres:latest
    container_name: postgres
    env_file: ./airflow/airflow.env
    volumes:
      - postgres_db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    networks:
      - rta-network

  # Application services
  broker:
    build:
      context: ./broker
    image: broker:latest
    container_name: broker
    depends_on:
      - kafka
      - mongodb
    env_file: .env
    volumes:
      - ./consumer:/app
    restart: "no"
    networks:
      - rta-network

  analyzer:
    image: analyzer:latest
    container_name: analyzer
    build:
      context: ./analyzer
    depends_on:
      - broker
    env_file: .env
    restart: on-failure
    networks:
      - rta-network

  consumer:
    build:
      context: ./consumer
    image: consumer:latest
    container_name: consumer
    depends_on:
      - analyzer
    env_file: .env
    volumes:
      - ./consumer:/app
    restart: on-failure
    networks:
      - rta-network

  # Airflow
  airflow-webserver:
    image: apache/airflow:3.0.1-python3.12
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    env_file: .env
    ports:
      - "8081:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    user: "${AIRFLOW_UID:-50000}:0"
    command: api-server
    networks:
      - rta-network
  
  airflow-scheduler:
    image: apache/airflow:3.0.1-python3.12
    container_name: airflow-scheduler
    restart: on-failure
    depends_on:
      - airflow-webserver
      - postgres
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/requirements.txt:/opt/airflow/scripts/requirements.txt
      - ./airflow/init.sh:/opt/airflow/init.sh
      - airflow_python_files:/home/airflow/.local
    env_file: .env
    user: "${AIRFLOW_UID:-50000}:0"
    entrypoint: /opt/airflow/init.sh
    command: scheduler
    networks:
      - rta-network
    
  airflow-triggerer:
    image: apache/airflow:3.0.1-python3.12
    container_name: airflow-triggerer
    restart: always
    depends_on:
      - airflow-scheduler
    env_file: .env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    user: "${AIRFLOW_UID:-50000}:0"
    command: triggerer
    networks:
      - rta-network

  airflow-dag-processor:
    image: apache/airflow:3.0.1-python3.12
    container_name: airflow-dag-processor
    restart: always
    depends_on:
      - airflow-scheduler
    env_file: .env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    user: "${AIRFLOW_UID:-50000}:0"
    command: dag-processor
    networks:
      - rta-network

  # Backedend 
  api:
    container_name: api
    image: api:latest
    build:
      context: ./api
    ports:
      - "5000:5000"
    depends_on:
      - consumer
    env_file: .env
    restart: on-failure
    networks:
      - rta-network
  
  # Frontend

volumes:
  mongodb_data:
  postgres_db:
  kafka-data:
  zookeeper-data:
  zookeeper-log:
  airflow_python_files:

networks:
  rta-network: